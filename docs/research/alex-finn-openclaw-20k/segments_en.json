[
  "I just spent $20,000 on OpenClaw and plan on spending another $100,000 on it by the end of the year. I truly believe the return on investment on all of these Mac Studios I'm buying is going to be at least 10x what I'm spending. You might think I'm crazy, but if by the end of this video I don't have you convinced what I'm doing is actually genius, then I think you're the crazy one. In this video I'll go over what I just spent all that money on, what my OpenClaw is doing on all this new hardware I just bought, why I believe this is the future, and show you how you can start doing the exact same thing I'm doing without spending a dollar on any hardware. You can use the exact Mac Mini you bought or even the dusty HP laptop from your closet. You are about to get a peek into the future of AI agents.",
  "Let's get into it. So real quick, we're going to cover a bunch in this video. Chapters down below if you want to skip around. But basically what we're going to be doing is I'm going to tell you why I spent all this money to run local AI models, what all the advantages are, what this is going to allow me to do. I'm going to give you a demo of exactly what I'm building, which I promise you, you have never seen anything like this in your life. There is nobody else on planet Earth building what I'm building with OpenClaw at the moment. I'm going to show you how this will change the entire world and why I believe all normal people will be running out to buy thousands of dollars worth of computers by the end of the year. And at the very end of the video, we'll go through how you can do the same thing I'm doing on a much smaller budget. Even if you have a $500 Mac mini or a $10 HP laptop in your closet",
  "I'll show you which local models you can run so you can start doing something similar to what I'm doing. I'm about to take you through a glimpse of what I think the future of AI agents are, what I think the future of OpenClaw is, and what I just think the future of AI is. You're going to learn a ton and your mind is going to be blown by what these AI models are capable of. So here's where we're going to start. The $20,000 I spent is on two Mac Studios. These are Mac Studios with 512 gigabytes of unified memory each. Why 512 gigabytes of unified memory each? So that I can run the largest, smartest local AI models in the world. Right now, that is Kimi K 2.5. Kimi K 2.5 is 600 gigabytes.",
  "Which means I need to load 600 gigabytes into local memory. With two Mac Studios at 512, that's a terabyte of AI models I can load into local memory. If I were to do the same thing with NVIDIA GPUs, I'd need to spend over $100,000 on NVIDIA GPUs. But I can do that with the unified memory of Mac Studios. Now why do I want to run large local models on my computers on these Mac Studios? Well here are the five reasons why. One, you run these models completely for free. I'm not paying for API costs anymore. When you use Claude Opus or ChatGPT or any other AIs that are in the cloud, you pay for every single token. These local models, because they're running on my Mac Studios,",
  "They are completely free to run. And because they are completely free to run, I can have them work 24-7, 365. This is an absolutely massive advantage. The number one objection I get when I tell people I'm doing this is, oh, local models, they're stupider than cloud models. KimiK 2.5 is not as smart as Opus. It's not as smart as ChatGPT 5.3. And you know what? You're 100% right. But here's the thing. The fact that I can run these AI models 24-7 completely changes what AI is capable of. Now I'm going to show you examples once we get through this. I'm going to show you my actual setup I'm building with these Mac Studios. But the fact that these AI models can now run 24-7, 365 means I can do things like",
  "Have them read Twitter and Reddit all day and all night looking for challenges. Have them coding all day and all night building solutions to those challenges. Have them shipping those apps all day and all night promoting them on all the social media. I can constantly be creating value from midnight to midnight every single day. They don't have to eat, they don't have to sleep, they don't cost me any money. It's literally like having 24/7 employees working for you that never complain, never demand more money out of you. They just have that upfront cost of buying the computer. And it doesn't matter that they're dumber than Opus. I can't do what I just described and what I'm going to show you later in this video with Opus. If I were to do this with Claude Opus or ChatGBT,",
  "I'd be spending at least $10,000 a month on API costs, but because I can run this locally, I can have these models going all the time, finding challenges, building solutions to challenges, and creating value for me and my company. There's many other reasons why you'd be wanting to run local models. Privacy, for instance, everything that happens, happens on the computer. Nothing goes to the cloud. Nothing goes to chat GPT servers. None of this can be read by Sam Altman or the owners of the other AI companies. Everything is completely private. In fact, I can unplug my computers right now if I wanted from the internet, and they'd still be going and running AI models. There's no internet required. It's all private, all local. No one can see what I'm doing. Next, it's educational. By running these local models, I'm learning how AI works. I'm learning a ton about what goes into running an AI model. I am learning about the most important technology in the entire world, and that in itself is worth a lot of money. And lastly,",
  "It's just fun AF. It is just so much fun looking down at your desk, seeing computers running, and knowing there are AI agents running, doing things for you 24-7. It is fun, and I don't care what other people say. You're allowed to have fun in this world. You're allowed to spend money to have fun. You're allowed to do things for the fun of it. Don't let people tell you you're not allowed to have fun anymore. Take it from me, you're allowed to have fun, and so that is another reason why I'm doing this. So what exactly am I building with all these local models running 24-7? Well, have a look at this. This is my company. This is my one-person, 24-7, 365 AI agent company, and this might look strange, but let me walk through exactly what's happening here. What you see here are my AI agents, and they are working as we speak. They are reading X. They are going through Reddit. They are searching for problems to solve. They are reading my tweets. They're watching my YouTube videos. They're looking at the performance of all my content, and as you can see, sometimes the agents even meet up together, go to a meeting table, and have discussions. Right now, there is a stand-up happening for all my AI agents where they are brainstorming.",
  "New features for CreatorBuddy. I can track the live activity, so you can see the live activity over the last hour. A round table started to brainstorm new features. They're all coming up with new ideas for features for CreatorBuddy. At some point, they will be handed off to Henry, who is the manager, the strategic manager of all the AI agents. If we take a look at the org chart of this AI digital company, of all these local models running and talking to each other and planning at all times, you can see I'm at the top as the CEO. Henry is the chief of staff. He's running on Opus 4.5, but all he's doing is getting ideas and approving and disproving. He just has to do a couple prompts a day where he approves or disproves ideas the local models hand to him.",
  "As you can see right now, he is in the stand-up brainstorming new features for Creator Buddy. Then I have my other agents working for me in this organization. So you can see I have a creative team, which all they are is a local model running on my Mac Studio, running off of Flux 2. That is able to generate images for me, thumbnails for my YouTube, images for my Twitter account. Whatever I need, that's all being done locally. I have my research team, which is Scout, who's an analyst, that is being powered by GLM 4.7, which is a huge local model that I am running on my Mac Studios. This is constantly reading Twitter, constantly reading Reddit, finding challenges to solve, and handing them to Henry, who is my chief of staff. And then I have many other agents working in my digital organization as well. I have an engineering team who is constantly coding for me, and many other AI agents.",
  "They are able to accomplish so many things. So for instance, right now, as they discuss new features for Creator Buddy, they're looking online, seeing what people want out of content tools, and building it out and discussing it with each other and learning from each other. And this goes much deeper than that. Each one of these agents have their own memories, have their own personalities, are building their own relationships with each other agent. If you look down here below, I have a list of all my agents. If I click on one of them, you can see here, Quill has its own soul, so its own personality, how they think, their own signature phrases, their own voice of how they talk, their own speaking style, their own responsibilities, even has their own relationships with",
  "The other AI agents. Every time one of my agents speaks to another agent, it actually changes their relationship. They can become better friends. They can become bitter enemies. It's just like a real workplace where you have friends, you have coworkers you like, you have coworkers you don't like, and their relationships can shift and evolve over time. They also have their own memories. So Quill is a new agent I just hired just now, so it doesn't have its own insights and strategies. But as they participate in meetings, as they have conversations with other agents, they can come up with their own insights and strategies. So for instance, Quill is my creative agent who writes tweets. Maybe Quill goes in and has a water cooler conversation with Scout, who is my local model who is constantly reading Twitter, and Scout tells them, hey, that tweet you wrote the other day, it's performing really well. Quill can then get a memory that says, okay, tweets like this perform really well. I need to write more about them.",
  "So my digital society here, my digital office, they're constantly learning from each other. They're constantly talking to each other. They can do many things. They can even have water cooler conversations, which you just saw there. They're now walking over to the water cooler and talking to each other. This happens all autonomously 24-7-365. They are constantly researching, constantly writing, creating, coding. They are constantly learning from each other. They're constantly building relationships with each other. And I don't need to be a part of this. I can just sit back and enable them and make sure they're doing good work. When I'm sleeping, they're working. When I'm eating, they're working. When I'm watching the Patriots win the Super Bowl, which this will look really bad if they don't end up winning the Super Bowl today, they are talking to each other and working and creating. This is only possible",
  "with local models. If this were all done with Opus, if all of these AI agents were Opus and ChatGBT, I'd be spending the cost of these Mac Studios every single month. But because I have local models working, I can offload a lot of this work to those local models to save tremendous amounts of money. And yes, I still have Opus as a part of this, but Opus Henry, the chief of strategy, is only doing decision-making. He isn't doing the dirty work. He isn't searching Twitter and searching Reddit and doing a lot of the writing and creating. He just approves and disproves. Everyone else is doing the hard work. All the tokens are being burnt by the local models. As I buy more computers, as I buy more GPUs and devices, which I fully plan on doing, I'm going to buy the Mac Studio M5 Ultra when that comes out in a few months. I'm going to buy a DGX Spark. I'm going to buy a whole lot of other computers. By the way, NVIDIA, if you're watching, send me the DGX Spark. I will talk about it so much. I will be adding all these devices to my organization, to my local data center. And as I do that, I can run more local models. I can expand my one-person company. I can get more employees in here.",
  "Just chugging and working 24-7. I can even, as I add more GPUs, train my own custom models. Basically train my own employees that will be working in my company. In a second right after I go through this I'll show you how you can run your own local models even if you have really crappy computers or a Mac Mini or anything. I'll show you how to run that in a second. But just to wrap this part up, this is the future of AI agents. Claude Bott unlocked this. Claude Bott unlocked the ability to run your own agents autonomously. The issue was you can't take full advantage of Claude Bott with APIs and cloud models. The bottleneck once models can run autonomously is the cost of the models themselves. But by running these models locally that bottleneck disappears. Your models can now be completely unchained.",
  "And do so many more use cases, like constantly finding challenges online, like constantly building and coding and creating things, like constantly reviewing all your work. This is the future of AI agents, and this is the worst it will ever be. Right now, the best local model is KimiK 2.5, which is near Opus 4.5 level. Over time, and probably by the end of the year, the local models will be better than that. They'll be better than that and be able to run on much cheaper hardware. This is the slowest, dumbest, and most expensive it will ever be, and right now, this has been amazing for me and what I've been able to accomplish. Another one of the biggest questions I get is like, okay, that all sounds cool, but like what are you actually getting out of all this? What are the workflows that you're able to enable that you weren't able to do before?",
  "Let me give you a couple examples here. So here's two examples. You can just go straight down here. Here's a couple things we've been doing. Number one, I have a researcher agent, which is a local model, constantly reading Reddit 24-7, 365. It finds challenges people are having in subreddits. It hands it to my strategy officer, which is Henry. Henry decides if the challenge is good or not. He takes the good challenge and hands it to the developer agent. The developer agent then codes an app to solve that challenge. The developer agent then ships that app and puts it live on Vercel through the Vercel CLI. Then the researcher agent DMs the original poster and says, hey, we came up with a solution to this problem. This is just a constant closed loop I do not need to be a part of that is constantly going 24-7, 365.",
  "This is not possible with cloud APIs. Here's another example. I record a YouTube video. Just a raw YouTube video. A local agent edits the video so it cuts out all the blank space. That is then handed to a local image model, Flux2, that is running locally on my device. That generates a thumbnail for the video. Another agent goes in the browser, puts the video onto YouTube, puts the chapters, posts the video. A day later, all my agents meet, they go to the table I showed you before, and they discuss the performance. They go over the transcript. What did he talk about? The hook? The thumbnail? What worked? What didn't work? And based on all those learnings, which get saved to their memory, they write a new script.",
  "These are the type of autonomous use cases that were not possible before. They were not possible with ChatGPT. They were not possible with ClaudeBot just using cloud APIs. It's only possible by having compute on your desk 24-7. This is what I can do now. This is what I'm developing. And this is what you can do in the new world as you start running your own local AI models. So now the question becomes, hey Alex, do I need to spend $20,000? That's a lot of money. I can't afford that right now. I need to be able to run local models and do these use cases without spending all that money. Well, I got good news for you. You can do this without spending $20,000. Can you do it to the degree, the intelligence, and the speed?",
  "at which my models are doing it. No, but you can start off cheap and then slowly layer on from there. Let me show you. So let's talk about which local models you can run on different budgets. You don't need to spend $20,000 like I have. You can have different budgets and different local models on each. Now, are the cheaper ones going to be as smart, efficient, fast as the larger ones? No, but it's good to start somewhere. And then as you go, as you figure out new use cases, as you figure out how to fit this into your workflow, you can either buy more hardware or change things around or experiment. It's up to you. I don't recommend everyone just go out and spend $20,000 like I did. No, I do not recommend that. Start cheap and slowly build your way up. So if your budget's only $100, that's great. You can buy a Raspberry Pi. On there, you can run",
  "Simple, small, local models like Gemma, like tiny llama, things like that. And you can do different things. You can have simple chats. You can do smart home things. You can do very simple things. There are use cases there. As your budget goes up, you can do more interesting use cases. So if you went out and you're like many people like myself that bought a Mac mini, when you discovered OpenClaw, you can run models too. There's llama models, there's mistral models, there's quen models you can run that could be like personal assistants that can do a little bit of coding. Will it be as good as Claude code? No, but you can still do some small things on it. If you have a larger budget and you buy maybe the top of the line Mac mini, you can start doing some more serious coding. You can start doing some more serious research.",
  "Maybe your model now starts reading Reddit at all times like mine. By the way, as I get into the upper tiers, if you learned anything at all, leave a like down below. Make sure to subscribe and turn on notifications. I'm going to be making so many videos about these use cases and about what I'm building. It'll blow your mind. Make sure to turn on notifications for that. Let me know down below in the comments if there's any specific part of this you want to hear more about, whether it's running cheaper local models, whether it's about running more expensive ones, use cases for this, open clause as a whole. Let me know which one you want me to dive deeper into for my next video. As your budget increases, maybe you buy a Mac Studio M2 Ultra, which is the older generation. You can start doing more professional workflows, have multiple agents going at once.",
  "And then once you get to my level where I'm at now with the Mac Studio M3 Ultra, so I have two of these M3 Ultras. One's on my desk now, another's coming in the mail this week. You can start having a fully autonomous organization working for you, which is amazing. And run local models that are almost as good as Opus, right? And almost as good as just good enough if it can run 24-7. This is the future. And this might not look like much right now what I'm showing you, but I am actively building this out as we speak. I'm actively building out more use cases. Nobody else in the world is doing anything like this. I'm not kidding. Where we are in technology right now is absolutely unbelievable. This is all green field. This is a brand new technology. OpenClaw only became popular like two weeks ago. We are two weeks into this revolution.",
  "If you go in now, if you tinker now and experiment now and try new things out, the odds are you're doing something no one else in the entire world has done. It is early on in these technology revolutions where all the opportunity is. I'm being serious. This is where all the opportunity is. If you strike now and you experiment, try new things, invest, dedicate yourself to this, you could create success and opportunity for yourself that no one has ever seen before. That's what I'm doing. That's why I went all in and invested in my own personal local data center here because I want to do things the world has never seen before. And it's something you can do as well. If you're joining me on this journey into the unknown, if you're joining me on pushing the limits of technology",
  "If you're joining me on trying to build the first one-person billion-dollar business, make sure to subscribe. Make sure to turn on notifications. I'll be taking you through this. I'm not holding back any secrets whatsoever. Everything I do, I will show to you, and you can copy and join along with me and do incredible things. I hope you learned something. I absolutely love making these videos for you. Thanks for joining along for this journey, and I will see you in the next one."
]